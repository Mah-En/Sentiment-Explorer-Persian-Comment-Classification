{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CijLeySYChpW"
   },
   "source": [
    "<div dir=\"center\">\n",
    "  <h1 align=\"center\" style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "    <font face=\"vazir\" color=\"#0099cc\">\n",
    "      Sentiment Explorer\n",
    "    </font>\n",
    "  </h1>\n",
    "</div>\n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  In this exciting project, my task was to preprocess Persian text data and prepare it for training a sentiment classification model. This project served as an exceptional opportunity to challenge my skills and put into practice the knowledge I had acquired so far. The success of the project depended heavily on the quality of the prepared data, and I was determined to ensure that the preprocessing phase was handled with precision and care.\n",
    "</p>\n",
    "\n",
    "------\n",
    "\n",
    "<h1 dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  <font face=\"Times New Roman\" color=\"#0099cc\" size=\"4\">\n",
    "    Project Phases:\n",
    "  </font>\n",
    "</h1>\n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  The project was carried out in three main stages:\n",
    "  <div dir=\"ltr\">\n",
    "    <ul>\n",
    "        <li><strong>Analysis of the Training Dataset:</strong>\n",
    "        <ul>\n",
    "          <li>Data Cleaning: Removal of redundant or irrelevant entries.</li>\n",
    "          <li>Dataset Preprocessing: Converting categorical sentiment labels into numerical values.</li>\n",
    "        </ul>\n",
    "      <li><strong>Text Preprocessing:</strong>\n",
    "        <ul>\n",
    "          <li>Normalization: Applying Persian text normalization techniques.</li>\n",
    "          <li>Tokenization: Splitting text into words or sentences.</li>\n",
    "          <li>Number Removal: Eliminating both Persian and Latin numerals.</li>\n",
    "          <li>Punctuation Removal: Removing punctuation marks such as <code>?</code>, <code>!</code>, etc.</li>\n",
    "          <li>Stopword Removal: Filtering out high-frequency, low-importance words.</li>\n",
    "          <li>Stemming: Reducing words to their root forms.</li>\n",
    "          <li>Extra Space Removal: Ensuring consistent word and sentence spacing.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><strong>Word Embedding:</strong>\n",
    "        <ul>\n",
    "          <li>Using <code>Word2Vec</code> to transform words into numerical vector representations.</li>\n",
    "          <li>Analyzing word similarity based on embeddings.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><strong>Preparation for Analysis:</strong>\n",
    "        <ul>\n",
    "          <li>Storing preprocessed data and embeddings for later use in machine learning models.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><strong>Sentiment Classification Model Training:</strong>\n",
    "        <ul>\n",
    "          <li>Data Splitting: Dividing the dataset into <code>Train</code> and <code>Validation</code> subsets.</li>\n",
    "          <li>Model Training: Using Logistic Regression to train the sentiment classifier.</li>\n",
    "          <li>Model Evaluation: Assessing performance on the validation dataset.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li><strong>Project Evaluation File Preparation:</strong>\n",
    "        <ul>\n",
    "          <li>Prediction on <code>Test</code> data: Predicting sentiment labels for the test dataset.</li>\n",
    "          <li>Creating the final evaluation file for submission.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</p>\n",
    "\n",
    "-----------\n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  <font face=\"Times New Roman\" size=\"3\">\n",
    "    Due to the need for quality assurance and considering my current proficiency level in <strong>data analysis</strong>, <strong>data preprocessing</strong>, and <strong>machine learning</strong>, certain core stages of the project were handled by the project team. These included:\n",
    "    <div dir=\"ltr\">\n",
    "      <ul>\n",
    "        <li><strong>Analysis of the Training Dataset:</strong> Performing initial data exploration and extracting relevant insights.</li>\n",
    "        <li><strong>Preparation for Analysis:</strong> Establishing an optimal framework for efficient data utilization.</li>\n",
    "        <li><strong>Sentiment Classification Model Training:</strong> Implementing and optimizing the machine learning model.</li>\n",
    "        <li><strong>Evaluation File Preparation:</strong> Compiling the final evaluation report for performance assessment.</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "  </font>\n",
    "</p>\n",
    "\n",
    "----------------\n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  Now it was time to demonstrate my skills and successfully overcome this challenge. I approached the project with diligence and determination to meet the required standards, and I am confident in the robustness of the prepared dataset and preprocessing pipeline.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6ofxVj2S1Wo"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  To begin the work, I placed the two dataset files, <code>train.csv</code> and <code>test.csv</code>, in the <code>data</code> directory. As the first step, I imported these files into my programming environment using the following commands:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "goPwV3upmfgz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KerargItZMKD"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  The datasets provided to me had already undergone a cleaning process, ensuring that no redundant or irrelevant entries were present. However, in order to gain a better understanding of the dataset, I decided to extract some useful insights using the following commands. These insights included the distribution of comments that recommended a purchase versus those that did not, as well as the overall structure of the dataset.<br>\n",
    "  This information helped me develop a clearer understanding of the data and prepared me for the subsequent stages of the project.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQ6S5951oH7q",
    "outputId": "41508db8-7d06-4390-9634-70cf72613310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 149400 entries, 0 to 149399\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   body                   149400 non-null  object\n",
      " 1   recommendation_status  149400 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lz3hKePGakta",
    "outputId": "0d067ad1-5228-46b2-b7e9-ec5740207937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   body    600 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "_86nqD-4a0b-",
    "outputId": "b5036a43-c4c8-416e-8b06-6bd372343078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendation_status\n",
       "not_recommended    49800\n",
       "recommended        49800\n",
       "no_idea            49800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['recommendation_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGmiqVX0awO3"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  Upon examining the data in the <code>recommendation_status</code> column, I found that its current format was not suitable for training machine learning models, as these algorithms require numerical input. Therefore, the next step was to convert the values in this column into numerical form, specifically <code>0</code> and <code>1</code>, so they could be utilized effectively by the models.  \n",
    "  To accomplish this transformation, I used the following commands:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_yuzGz_sYQSv"
   },
   "outputs": [],
   "source": [
    "train_data[\"recommendation_status\"] = train_data[\"recommendation_status\"].map({\"no_idea\": 2,\"recommended\": 1, \"not_recommended\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R47YonnlZDn1",
    "outputId": "59e73a06-bcc8-4966-fcc3-d2968754ca55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"recommendation_status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "IVGZ1IeKCXIK",
    "outputId": "adb4f75a-ab5e-4543-bee2-16f598ff2e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendation_status\n",
       "0    49800\n",
       "1    49800\n",
       "2    49800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"recommendation_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoueKN1UZSeO"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  At this stage, it was my turn to take action. Using the knowledge and tools I had learned so far, I implemented the required preprocessing steps for the Persian language in the form of a function named <code>preprocess_text</code>.  \n",
    "  This function was designed to perform all preprocessing operations mentioned at the beginning of the project, including text normalization, tokenization, stopword removal, stemming, and other necessary steps.  \n",
    "  The <code>preprocess_text</code> function could then be applied to any text input, enabling me to preprocess my dataset effectively for the subsequent stages of the project.  \n",
    "  Below is an example demonstrating the expected behavior of this function:\n",
    "</p>\n",
    "\n",
    "**Input:**\n",
    "<pre>\n",
    "  <code>\n",
    "example = \"من متولد سال ۱۳۷۷ هستم\"\n",
    "preprocess_text(example)\n",
    "  </code>\n",
    "</pre>\n",
    "\n",
    "**Output:**\n",
    "<pre>\n",
    "  <code>\n",
    "['متولد', 'سال', 'هس']\n",
    "  </code>\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4ZVBLIQZbvl",
    "outputId": "423e63bd-3cbc-44dc-d2c2-9ff9180e61c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: hazm in /Users/mahla/Library/Python/3.9/lib/python/site-packages (0.10.0)\n",
      "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (0.9.2)\n",
      "Requirement already satisfied: flashtext<3.0,>=2.7 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (2.7)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (4.3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (3.9.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (1.24.3)\n",
      "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (0.9.11)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from hazm) (1.6.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (3.0.0)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (58.0.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.3.0.post1)\n",
      "Requirement already satisfied: click in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.6.0)\n",
      "Requirement already satisfied: wrapt in /Users/mahla/Library/Python/3.9/lib/python/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.17.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahla/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import hazm\n",
    "from hazm import Normalizer, Stemmer, Lemmatizer, word_tokenize\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "H11x9yMlZpEm"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = normalizer.normalize(text)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMJRqvYb3p1m"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  After completing the implementation of the preprocessing function, the next step was to apply this operation to all the reviews stored in the <code>train_data</code> dataset so that they would be ready for reference by the <code>Word2Vec</code> model.  \n",
    "  The preprocessed data was then stored in a new column named <code>preprocess</code> for future use.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c1THStUUhv-8"
   },
   "outputs": [],
   "source": [
    "dataes = train_data['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "AHWx8D8Nh60l"
   },
   "outputs": [],
   "source": [
    "data_processed = dataes.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "E6Ug9pdViA2u",
    "outputId": "d1c619b9-6fc6-421c-9315-3014ec97278e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>recommendation_status</th>\n",
       "      <th>preprocess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>جنسش‌خوب‌بود‌خیلی‌بدبدبود</td>\n",
       "      <td>0</td>\n",
       "      <td>[جنسش‌خوب‌بود‌خیلی‌بدبدبود]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>به کار میاد شک ندارم</td>\n",
       "      <td>1</td>\n",
       "      <td>[به, کار, میاد, شک, ندار]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>چیزی ک توعکسه واست میفرستن ولی هم جنسش خوب نیس...</td>\n",
       "      <td>2</td>\n",
       "      <td>[چیز, ک, توعکسه, واس, میفرستن, ول, ه, جنس, خوب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>رنگش خیلی خوبه . براق هم هست و زود خشک میشه . ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[رنگ, خیل, خوبه, براق, ه, هس, و, زود, خشک, میش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من مرجوع کردم قسمت پاچه شلوار برام تنگ بود ولی...</td>\n",
       "      <td>2</td>\n",
       "      <td>[من, مرجوع, کرد, قسم, پاچه, شلوار, برا, تنگ, ب...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  recommendation_status  \\\n",
       "0                          جنسش‌خوب‌بود‌خیلی‌بدبدبود                      0   \n",
       "1                               به کار میاد شک ندارم                      1   \n",
       "2  چیزی ک توعکسه واست میفرستن ولی هم جنسش خوب نیس...                      2   \n",
       "3  رنگش خیلی خوبه . براق هم هست و زود خشک میشه . ...                      2   \n",
       "4  من مرجوع کردم قسمت پاچه شلوار برام تنگ بود ولی...                      2   \n",
       "\n",
       "                                          preprocess  \n",
       "0                        [جنسش‌خوب‌بود‌خیلی‌بدبدبود]  \n",
       "1                          [به, کار, میاد, شک, ندار]  \n",
       "2  [چیز, ک, توعکسه, واس, میفرستن, ول, ه, جنس, خوب...  \n",
       "3  [رنگ, خیل, خوبه, براق, ه, هس, و, زود, خشک, میش...  \n",
       "4  [من, مرجوع, کرد, قسم, پاچه, شلوار, برا, تنگ, ب...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"preprocess\"] = data_processed\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gfv4DVk9pgNM"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  With the preprocessing applied to the data and the results stored, the next step was to perform word embedding using the <code>Word2Vec</code> algorithm.  \n",
    "  In this stage, I implemented the <code>Word2Vec</code> model to train on the preprocessed dataset and convert each word into its corresponding numerical vector representation.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4pTpsNCOaeA8"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=train_data['preprocess'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['و', 'بود', 'به', 'خیل', 'از', 'خوب', 'که', 'من', '،', 'رو', 'ول', 'برا', 'با', 'نیس', 'ه', 'این', 'خوبه', 'داره', 'جنس', 'در']\n"
     ]
    }
   ],
   "source": [
    "print(list(model.wv.key_to_index.keys())[:20])  # First 20 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WkzyWBsrk3w"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  Next, I tested the trained <code>Word2Vec</code> model to find the words most similar to the word \"دوست\" (\"friend\").  \n",
    "  I then examined and analyzed the resulting output to assess the model’s ability to capture semantic similarities between words.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gimbEMP5f1_r",
    "outputId": "f02941cd-56a3-4f16-a765-f9fa5de62151"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('دوسشون', 0.8856764435768127),\n",
       " ('دوستشون', 0.8643873333930969),\n",
       " ('دوس', 0.8094560503959656),\n",
       " ('اصرار', 0.7310218811035156),\n",
       " ('التجار', 0.7246741652488708),\n",
       " ('برندک', 0.6936068534851074),\n",
       " ('انتظارشو', 0.6874205470085144),\n",
       " ('ضدگ', 0.6769317984580994),\n",
       " ('نمی\\u200cگذ', 0.6706246137619019),\n",
       " ('سایزمتوسط', 0.6700646877288818)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"دوست\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pm4-k8lG6waa"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  At this stage, I designed the <code>sentence_vector</code> function to compute the embedding vector for each review.  \n",
    "  The purpose of this function is to calculate the average of the word vectors within a review and generate a single unified vector representing the entire sentence.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nSQep3ve60cW"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "G7W8myxB64l7"
   },
   "outputs": [],
   "source": [
    "def sentence_vector(sentence):\n",
    "    vectors = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            vectors.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            vectors.append(np.zeros(100))  \n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSVcMHO1u417"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  Now that the <code>sentence_vector</code> function has been defined, I applied it to the <code>train_data['preprocess']</code> column.  \n",
    "  The resulting sentence-level vectors were stored in a variable named <code>sentence_vectors</code>.  \n",
    "  At this point, each review was successfully transformed into a corresponding vector, ready to be fed into the classification model.\n",
    "</p>\n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">\n",
    "  <pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">\n",
    "# Applying the sentence_vector function to the preprocessed data\n",
    "sentence_vectors = train_data['preprocess'].apply(sentence_vector)\n",
    "  </pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "LoBDtIP_67u0",
    "outputId": "2054b68b-2a1d-4223-80e6-2801d8c8c72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [-0.008517253, -0.0070543014, 0.0036804832, 0....\n",
       "1         [-0.5518608, 1.0812774, 0.4363729, 0.29245153,...\n",
       "2         [0.13355035, 0.65368444, -0.08094742, 0.575277...\n",
       "3         [0.43473572, 0.94272953, 0.080585, 0.900239, -...\n",
       "4         [0.22311734, 1.4037535, -0.06941506, 0.9825201...\n",
       "                                ...                        \n",
       "149395    [-0.22422612, 0.6290177, -0.36410323, 0.151405...\n",
       "149396    [0.40184224, 0.92359227, -0.082991086, 0.49892...\n",
       "149397    [-0.459879, 0.59306884, 0.69628364, 0.6988099,...\n",
       "149398    [0.9055585, 0.828592, -0.4419861, 0.93607205, ...\n",
       "149399    [0.14473574, 1.2291144, -0.28592607, 0.869558,...\n",
       "Name: preprocess, Length: 149400, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors = train_data['preprocess'].apply(sentence_vector)\n",
    "sentence_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_nNKqw47JI-"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  In this step, I used the <code>train_test_split</code> function to divide the data into training and evaluation sets.  \n",
    "  The data was split in such a way that 80% was allocated for training and 20% for evaluation.  \n",
    "  Here, <code>X</code> represents the embedded sentence vectors for each review, and <code>y</code> contains the target labels, which correspond to the <code>recommendation_status</code> column.\n",
    "</p>\n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">\n",
    "  <pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Converting sentence vectors to a NumPy array\n",
    "X = np.array(sentence_vectors.to_list())\n",
    "# Assuming df[\"recommendation_status\"] contains the target labels\n",
    "y = df[\"recommendation_status\"].values\n",
    "# Splitting the data into training and evaluation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  </pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2zsKKt9d7E1F"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(sentence_vectors.to_list())\n",
    "\n",
    "y = train_data[\"recommendation_status\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aEzJHT27Sih"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  After preparing and splitting the dataset into training and evaluation sets, the next step was to train the model.  \n",
    "  In this project, I used the <i>Logistic Regression</i> algorithm for sentiment classification.  \n",
    "  The model was trained using the <code>fit</code> method, applied to the training data <code>X_train</code> and <code>y_train</code>.\n",
    "</p>\n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">\n",
    "  <pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence\n",
    "logistic_model.fit(X_train, y_train)\n",
    "  </pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "ozUuSRR51xVx",
    "outputId": "3bc1282a-4b7f-42ca-f484-7071a0136afd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bA_YHi-77qox"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  After training the model, the next step was to evaluate its performance.  \n",
    "  In this stage, I used the evaluation data <code>X_test</code> to generate predictions, and then measured the model’s accuracy using the <code>accuracy_score</code> function.  \n",
    "  Finally, the model's accuracy was printed. The minimum acceptable threshold for accuracy was set at 50%.\n",
    "</p>\n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">\n",
    "  <pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Generating predictions using the evaluation data\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "# Evaluating model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "  </pre>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FnTkh_xy6TZ_",
    "outputId": "b802ea8e-96e5-4fb5-c4ed-3e48fbc38b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6733601070950469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKFFlYy40GzT"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  In this section, I used the <code>predict_recommendation</code> function to classify new reviews.  \n",
    "  This function processes the input review, converts it into an embedding vector, and then uses the trained model to predict the class of the review.  \n",
    "  It returns one of the following three outcomes:  \n",
    "  <ul>  \n",
    "    <li><code>recommended</code></li>  \n",
    "    <li><code>not_recommended</code></li>  \n",
    "    <li><code>no_idea</code></li>  \n",
    "  </ul>  \n",
    "</p>  \n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  To accomplish this task, I followed the steps below:  \n",
    "</p>  \n",
    "\n",
    "<ol dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  <li>Defined a new review. For example:  \n",
    "</ol>  \n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">  \n",
    "<pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">  \n",
    "comment = \"این محصول فوق‌العاده بود و واقعاً از خریدم راضی‌ام!\"  \n",
    "</pre>  \n",
    "</div>  \n",
    "\n",
    "<ol dir=\"ltr\" start=\"2\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  <li>Called the <code>predict_recommendation</code> function and stored the result:  \n",
    "</ol>  \n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">  \n",
    "<pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">  \n",
    "result = predict_recommendation(comment)  \n",
    "print(result)  \n",
    "</pre>  \n",
    "</div>  \n",
    "\n",
    "<ol dir=\"ltr\" start=\"3\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  <li>Tested several other reviews with different sentiments (positive, negative, and neutral), and evaluated the model's output. For instance:  \n",
    "</ol>  \n",
    "\n",
    "<div dir=\"ltr\" style=\"text-align: left;\">  \n",
    "<pre style=\"background-color: #f5f5f5; padding: 10px; border-radius: 5px; font-size: 14px; font-family: monospace; overflow: auto;\">  \n",
    "print(predict_recommendation(\"کیفیت این محصول بسیار پایین بود و اصلاً راضی نیستم.\"))  \n",
    "print(predict_recommendation(\"محصول معمولی بود، نه خوب و نه بد.\"))  \n",
    "</pre>  \n",
    "</div>  \n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium;\">  \n",
    "  My objective here was to assess the model’s performance by testing various review inputs and analyzing the differences in predictions.  \n",
    "  By modifying the review texts, I was also able to gain a deeper understanding of how natural language processing affected the outcome.\n",
    "</p>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Z8jLBFxK9t9O"
   },
   "outputs": [],
   "source": [
    "def predict_recommendation(comment):\n",
    "    preprocessed_comment = preprocess_text(comment)\n",
    "    \n",
    "    comment_vector = sentence_vector(preprocessed_comment)\n",
    "    \n",
    "    comment_vector = comment_vector.reshape(1, -1)\n",
    "    \n",
    "    prediction = logistic_model.predict(comment_vector)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2YU5n2J02Dj"
   },
   "source": [
    "<p dir=\"ltr\" style=\"direction: ltr;text-align: justify;line-height:200%;font-family:Times New Roman;font-size:medium\">\n",
    "  In the final prediction step, I applied the implemented function to the reviews in the <code>test</code> dataset.  \n",
    "  The predicted classes for each review were stored in a DataFrame named <code>submission</code>.  \n",
    "  This DataFrame was structured as shown below, containing a single column named <code>class</code> that specifies the predicted sentiment class for each review.  \n",
    "  This file directly influences the final evaluation of the project.\n",
    "</p>\n",
    "\n",
    "<table class=\"center\" style=\"border-collapse: collapse; width: 30%; text-align: center; font-family: Times New Roman; font-size: medium;\">\n",
    "  <tr style=\"background-color: #e0e0e0;\">\n",
    "    <th style=\"border: 1px solid #ccc; padding: 8px;\">class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ccc; padding: 8px;\">not_recommended</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ccc; padding: 8px;\">not_recommended</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ccc; padding: 8px;\">recommended</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"border: 1px solid #ccc; padding: 8px;\">...</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "u32cM4_T_NZN",
    "outputId": "3685b8b4-51bc-49f9-8e21-1b5405b722a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>not_recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>no_idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               class\n",
       "0        recommended\n",
       "1            no_idea\n",
       "2        recommended\n",
       "3        recommended\n",
       "4        recommended\n",
       "..               ...\n",
       "595      recommended\n",
       "596      recommended\n",
       "597  not_recommended\n",
       "598          no_idea\n",
       "599      recommended\n",
       "\n",
       "[600 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = test_data['body'].apply(predict_recommendation)\n",
    "submission = pd.DataFrame({'class':pre})\n",
    "submission = submission.replace({0: 'not_recommended', 1: 'recommended', 2: 'no_idea'})\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgrpwPUK2kHC"
   },
   "source": [
    "<h2 align=\"right\" style=\"line-height:200%;font-family:Times New Roman;color:#0099cc\">\n",
    "  <font face=\"Times New Roman\" color=\"#0099cc\">\n",
    "    <b>Answer Packaging Cell</b>\n",
    "  </font>\n",
    "</h2>\n",
    "\n",
    "<p dir=\"ltr\" style=\"direction: ltr; text-align: justify; line-height:200%; font-family:Times New Roman; font-size:medium\">\n",
    "  To generate the <code>result.zip</code> file, I executed the following cell.  \n",
    "  Please make sure that all recent changes in the notebook are saved (<code>Ctrl+S</code>) before running this cell, so that your code can be reviewed if support is needed.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGkOqnCM2BBo",
    "outputId": "64f2d7cb-8d51-484d-89d8-2f437a7f5ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['persian_comments_preprocessing.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    " \n",
    "if not os.path.exists(os.path.join(os.getcwd(), 'persian_comments_preprocessing.ipynb')):\n",
    "    %notebook -e initial.ipynb\n",
    "\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['persian_comments_preprocessing.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
